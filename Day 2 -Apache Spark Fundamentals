# Databricks AI Challenge â€“ Spark Basics

## About This Repository
This repository contains my learning and hands-on practice from the Databricks AI Challenge.  
I am a beginner exploring Apache Spark using Databricks Community Edition.

---

## Concepts Covered
- Apache Spark overview
- Spark DataFrame basics
- select() â€“ choosing required columns
- filter() â€“ applying conditions
- groupBy() â€“ grouping similar values
- count() â€“ counting number of rows
- orderBy() â€“ sorting data

---

## Dataset Used
- E-commerce events dataset (CSV format)
- Loaded using Spark DataFrame

---

## Sample Code
```python
# Load data
events = spark.read.csv(
    "/Volumes/workspace/default/ecommerce_data/2019-Oct.csv",
    header=True,
    inferSchema=True
)

# Select columns
events.select("event_type", "product_id", "price").show()

# Filter data
events.filter("price > 100").count()

# Group and count
events.groupBy("event_type").count().show()

# Order by count
events.groupBy("brand").count().orderBy("count", ascending=False).show()

## Sample Code
```python
# Load data
events = spark.read.csv(
    "/Volumes/workspace/default/ecommerce_data/2019-Nov.csv",
    header=True,
    inferSchema=True
)

# Select columns
events.select("event_type", "product_id", "price").show()

# Filter data
events.filter("price > 100").count()

# Group and count
events.groupBy("event_type").count().show()

# Order by count
events.groupBy("brand").count().orderBy("count", ascending=False).show()

---

## LinkedIn Post (Day 2 â€“ Apache Spark Fundamentals)
I documented my Day 2 learning from the Databricks AI Challenge on LinkedIn.

ðŸ”— **Post Link:**  
https://www.linkedin.com/posts/maddinareddisankeerthi_databrickswithidc-codebasics-indiandataclub-activity-7415710013400199168-uCwg?utm_source=social_share_send&utm_medium=member_desktop_web&rcm=ACoAAFxGtfwBB5nhO5M2F5A9lGeNvQx8T-786JY

ðŸ‘¤ **Author:** Maddina Reddi Sankeerthi
